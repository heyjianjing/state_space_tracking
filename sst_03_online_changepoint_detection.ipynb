{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "RXTo9PJLGaxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `changepoint` is an underlying shift in the parameters that generate a data sequence (e.g. the mean of a Gaussian suddenly jumps). Here, we focus on the online or causal task\n",
        "\n",
        "To do this, we introduce a latent variable named `run length` $r_t$, indicating the number of steps since the most recent changepoint\n",
        "\n",
        "Based on observation $x_t$, if a changepoint occurs at $t$, then $r_t=0$; otherwise it increments by 1\n",
        "\n",
        "We want to maintains full run length `posterior` $p(r_t|x_{1:t})$ and update this `recursively`\n",
        "\n",
        "In addition, we want to update the sequence `predictive distribution` for $x_{t+1}$ using only $x_{1:t}$\n"
      ],
      "metadata": {
        "id": "RyYZGXpDFiF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predictive distribution"
      ],
      "metadata": {
        "id": "ym9Sr6iSG_Ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using marginalization, we can write the `predictive` as\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "p(x_{t+1}|x_{1:t})&=\\sum_{r_t=0}^tp(x_{t+1}|r_t, x_{t-r_t:t})p(r_t|x_{1:t}) \\\\\n",
        "&=\\sum_{r_t}p(x_{t+1}|r_t, x_t^{(r)})p(r_t|x_{1:t})\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $x_t^{(r)}$ denotes the most recent portion of $x_{1:t}$ that belongs to the `current` run\n",
        "\n",
        "This indicates sequence predictive is determined by $p(x_{t+1}|r_t, x_t^{(r)})$ and run length posterior $p(r_t|x_{1:t})$\n",
        "\n",
        "$p(x_{t+1}|r_t, x_t^{(r)})$ is often refered to as underlying probabilistic model `(UPM) predictive` to distinguish it from sequence predictive $p(x_{t+1}|x_{1:t})$"
      ],
      "metadata": {
        "id": "vN9ST-GGHCIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run length posterior"
      ],
      "metadata": {
        "id": "zpxNKzVqJxxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute run length posterior, we use the expression for conditional probability and joint\n",
        "\n",
        "$$\\begin{align*}\n",
        "p(r_t|x_{1:t})&=\\frac{p(r_t, x_{1:t})}{\\sum_{r_{t'}}p(r_{t'},x_{1:t})}\n",
        "\\end{align*}$$\n",
        "\n",
        "We express the joint in a `recursive` manner\n",
        "\n",
        "$$\\begin{align*}\n",
        "p(r_t, x_{1:t})&=\\sum_{r_{t-1}}p(r_t, r_{t-1}, x_t, x_{1:t-1}) \\\\\n",
        "&=\\sum_{r_{t-1}}p(r_t, x_t | r_{t-1},  x_{1:t-1})p(r_{t-1}, x_{1:t-1})\\\\\n",
        "&=\\sum_{r_{t-1}}p(x_t|r_t, r_{t-1}, x_{1:t-1})p(r_t|r_{t-1}, x_{1:t-1})p(r_{t-1}, x_{1:t-1}) \\\\\n",
        "& \\text{assumption: } x_t \\text{ conditionally independent of } r_t \\\\\n",
        "& \\text{assumption: } r_t \\text{ conditionally independent of } x_{1:t-1} \\\\\n",
        "&=\\sum_{r_{t-1}}p(x_t|r_{t-1}, x_{1:t-1})p(r_t|r_{t-1})p(r_{t-1}, x_{1:t-1})\\\\\n",
        "&=\\sum_{r_{t-1}}p(x_t|r_{t-1}, x_{t-1}^{(r)})p(r_t|r_{t-1})p(r_{t-1}, x_{1:t-1})\\\\\n",
        "\\end{align*}$$\n",
        "\n",
        "Therefore, the joint at step $t$, $p(r_t, x_{1:t})$, depends on UPM predictive $p(x_t|r_{t-1}, x_{t-1}^{(r)})$ and joint $p(r_{t-1}, x_{1:t-1})$ at step $t-1$ plus a changepoint prior $p(r_t|r_{t-1})$"
      ],
      "metadata": {
        "id": "6_cUd86zJ1o1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is noted from derivation above that once we set the initial joint $p(r_0)$, what remains to be calculated is the UPM predictive and the changepoint prior"
      ],
      "metadata": {
        "id": "wdtilTHGRt1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conjugate models"
      ],
      "metadata": {
        "id": "e0w_Ly1jS2TZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The computation of UPM predictive leverages `conjugate model`\n",
        "\n",
        "Assume we have observations $D$, model parameters $\\theta$ and hyperparameters $\\alpha$. Then the prior predictive distribution marginalized over parameters can be written as\n",
        "\n",
        "$$p(x|\\alpha)=\\int p(x|\\theta)p(\\theta |\\alpha)$$\n",
        "\n",
        "where $p(x|\\theta)$ is `predictive model` given parameters and $(\\theta |\\alpha)$ is the prior of `parameters`\n",
        "\n",
        "This is called `prior predictive distribution` because this is the prediction `before` we observe any data (that is, $D$ is not taken into account)"
      ],
      "metadata": {
        "id": "1s1ErMYWS3tW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can write `posterior predictive distribution` as\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "p(x|D, \\alpha)&=\\int p(x|\\theta)p(\\theta |D, \\alpha) \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "A wonderful property of conjugate model is that the prior distribution and posterior distribution are of the same form. Therefore, if parameter prior is conjugate, then we have\n",
        "\n",
        "$$p(\\theta|D, \\alpha) = p(\\theta | \\alpha')$$\n",
        "\n",
        "Therefore\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "p(x|D, \\alpha)&=\\int p(x|\\theta)p(\\theta |D, \\alpha) \\\\\n",
        "&=\\int p(x|\\theta)p(\\theta |\\alpha')\\\\\n",
        "&=p(x|\\alpha')\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "That is, the posterior predictive distribution is the same as the prior predictive with only changed hyperparameters $\\alpha'$\n",
        "\n",
        "This allows us to bypass the whole integration thing is we can compute $\\alpha'$\n",
        "\n",
        "One family of conjugate model that is particularly attractive to efficiently compute $\\alpha'$ is the exponential family"
      ],
      "metadata": {
        "id": "AmSgonGpUI3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQlZx64VFXL3"
      },
      "outputs": [],
      "source": []
    }
  ]
}